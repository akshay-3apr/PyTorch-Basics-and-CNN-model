{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LearningPyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jo8vJjWY6cWf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo8vJjWY6cWf",
        "colab_type": "text"
      },
      "source": [
        "# Torch Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzniP-3jnFn0",
        "colab_type": "code",
        "outputId": "2e3d70f1-4059-40dc-cc65-be1d4ae3dc44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "#Construct a empty matrix, uninitialized\n",
        "x = torch.empty(5,3)\n",
        "print(\"Empty Tensor: \",x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "x = torch.rand(5,3)\n",
        "print(\"Random Initialized Tensor: \",x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "x = torch.zeros(5,3,dtype=torch.long)\n",
        "print(\"Tensor Initialized with Zeros: \",x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "x=torch.tensor([5.5,3],dtype=torch.long)\n",
        "print(\"Create tensor from data: \",x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "x=x.new_ones(5,3,dtype=torch.double)\n",
        "print('create a tensor based on existing tensor: ',x)\n",
        "x=torch.randn_like(x,dtype=torch.float)\n",
        "print('Create a random like tensor from exisitng tensor. x:',x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "#size of tensor\n",
        "print(\"Size of tensor: \",x.size())\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "#addition of two matrices\n",
        "x=torch.rand(5,3)\n",
        "y=torch.rand(5,3)\n",
        "print(\"Addition of tensor: \")\n",
        "print(\"1st tensor: \",x)\n",
        "print(\"2nd tensor: \",y)\n",
        "print('x+y: ',x+y)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "#converting tensor to numpy array\n",
        "print(\"After converting tensor x to numpy: \",x.numpy())\n",
        "print(\"X does not change: \",x)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")\n",
        "\n",
        "#converting numpy array to torch tensor\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "print(\"before converting a: \",a)\n",
        "b=torch.from_numpy(a)\n",
        "print(\"after converting a to tensor b: \",b)\n",
        "np.add(a,1,out=a)\n",
        "print(\"After addition a is: \",a)\n",
        "print(\"After addition of a, b also changes: \",a)\n",
        "print(\"\\n<\"+\"=\"*50+\">\\n\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty Tensor:  tensor([[1.4244e-36, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [1.4013e-45, 0.0000e+00, 1.0643e+15]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "Random Initialized Tensor:  tensor([[0.8536, 0.6576, 0.8152],\n",
            "        [0.8994, 0.2075, 0.1426],\n",
            "        [0.8389, 0.3819, 0.7531],\n",
            "        [0.4298, 0.0935, 0.5189],\n",
            "        [0.9103, 0.1960, 0.0477]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "Tensor Initialized with Zeros:  tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "Create tensor from data:  tensor([5, 3])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "create a tensor based on existing tensor:  tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "Create a random like tensor from exisitng tensor. x: tensor([[ 0.2837, -0.8725, -1.2388],\n",
            "        [ 1.5744,  0.2161, -0.0248],\n",
            "        [-1.1579, -0.3360,  0.8448],\n",
            "        [-1.5440, -0.4141, -0.4618],\n",
            "        [ 0.0371,  1.0200, -0.8501]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "Size of tensor:  torch.Size([5, 3])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "Addition of tensor: \n",
            "1st tensor:  tensor([[0.2011, 0.1860, 0.1746],\n",
            "        [0.0269, 0.7579, 0.1991],\n",
            "        [0.9329, 0.4447, 0.1035],\n",
            "        [0.1447, 0.9108, 0.9446],\n",
            "        [0.2344, 0.9216, 0.2134]])\n",
            "2nd tensor:  tensor([[0.8527, 0.5730, 0.8463],\n",
            "        [0.7740, 0.7369, 0.4722],\n",
            "        [0.9686, 0.9784, 0.3648],\n",
            "        [0.9019, 0.3522, 0.3251],\n",
            "        [0.6104, 0.9412, 0.8496]])\n",
            "x+y:  tensor([[1.0538, 0.7590, 1.0209],\n",
            "        [0.8009, 1.4949, 0.6714],\n",
            "        [1.9015, 1.4231, 0.4683],\n",
            "        [1.0467, 1.2630, 1.2697],\n",
            "        [0.8448, 1.8628, 1.0629]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "After converting tensor x to numpy:  [[0.20109361 0.1860236  0.17464525]\n",
            " [0.02690631 0.75794625 0.19913459]\n",
            " [0.932871   0.44468987 0.10347432]\n",
            " [0.14472288 0.91076475 0.9445553 ]\n",
            " [0.23438519 0.9215576  0.2133854 ]]\n",
            "X does not change:  tensor([[0.2011, 0.1860, 0.1746],\n",
            "        [0.0269, 0.7579, 0.1991],\n",
            "        [0.9329, 0.4447, 0.1035],\n",
            "        [0.1447, 0.9108, 0.9446],\n",
            "        [0.2344, 0.9216, 0.2134]])\n",
            "\n",
            "<==================================================>\n",
            "\n",
            "before converting a:  [1. 1. 1. 1. 1.]\n",
            "after converting a to tensor b:  tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "After addition a is:  [2. 2. 2. 2. 2.]\n",
            "After addition of a, b also changes:  [2. 2. 2. 2. 2.]\n",
            "\n",
            "<==================================================>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9klk3u8F-X6",
        "colab_type": "text"
      },
      "source": [
        "## Check if CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utz6X4DMIO5b",
        "colab_type": "code",
        "outputId": "7e737b41-ff82-4489-d0a8-1b2ab12b46f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2011, 1.1860, 1.1746],\n",
            "        [1.0269, 1.7579, 1.1991],\n",
            "        [1.9329, 1.4447, 1.1035],\n",
            "        [1.1447, 1.9108, 1.9446],\n",
            "        [1.2344, 1.9216, 1.2134]], device='cuda:0')\n",
            "tensor([[1.2011, 1.1860, 1.1746],\n",
            "        [1.0269, 1.7579, 1.1991],\n",
            "        [1.9329, 1.4447, 1.1035],\n",
            "        [1.1447, 1.9108, 1.9446],\n",
            "        [1.2344, 1.9216, 1.2134]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5aaN09dFsEl",
        "colab_type": "text"
      },
      "source": [
        "##Gradient Calculation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1La_JEK2FwFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da0eebf0-1c5e-40d2-d388-ab877865d1b5"
      },
      "source": [
        "import torch\n",
        "# Creating the graph\n",
        "# Only Tensors of floating point dtype can require gradi\n",
        "x = torch.tensor(1.0, requires_grad = True)\n",
        "z = x ** 3\n",
        "z.backward() #Computes the gradient \n",
        "print(\"Gradient Calculated: \",x.grad.data) #Prints '3' which is dz/dx "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient Calculated:  tensor(3.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-cG7-j6W55",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Neural Networks from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jti1MHnKpoCr",
        "colab_type": "text"
      },
      "source": [
        "##Importing Python and PyTorch Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCwVRawUpg-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIejfKxxpv-t",
        "colab_type": "text"
      },
      "source": [
        "## identify and specify the GPU as the device\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H9l26Ylpt6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7282a15a-0316-483b-9899-8b4f2ce52c1a"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "SEED = 19\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if device == torch.device(\"cuda\"):\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    print(\"GPU Name: \",torch.cuda.get_device_name(0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Name:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUs44XRxqK1_",
        "colab_type": "text"
      },
      "source": [
        "##Importing Training, Validation and Testing Data. Converting to type tensor and generating custom PyTorch DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4RbSDXgvIAp",
        "colab_type": "code",
        "outputId": "97273bad-6c11-49b6-824e-7706d13dd5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "test_dataset = dsets.MNIST(root='./data',transform=transforms.ToTensor(),train=False)\n",
        "test_inputs,validation_inputs,test_labels,validation_labels = train_test_split(test_dataset.data,\n",
        "                                                                                 test_dataset.targets,\n",
        "                                                                                 random_state=SEED,\n",
        "                                                                                 test_size=0.5,\n",
        "                                                                                 stratify = test_dataset.targets\n",
        "                                                                                 )\n",
        "\n",
        "print('test_inputs: ',len(test_inputs))\n",
        "print('validation_inputs: ',len(validation_inputs))\n",
        "print('test_labels: ',len(test_labels))\n",
        "print('validation_labels: ',len(validation_labels))\n",
        "\n",
        "# convert all our data into torch tensors, required data type for our model\n",
        "test_inputs = test_inputs.type(torch.float)\n",
        "validation_inputs = validation_inputs.type(torch.float)\n",
        "\n",
        "print(\"train dataset size: \",train_dataset.data.size())\n",
        "print(\"validation dataset size: \",validation_inputs.data.size())\n",
        "print(\"test dataset size: \",test_inputs.data.size())\n",
        "\n",
        "\n",
        "batch_size=100\n",
        "n_iters = 3000\n",
        "num_epochs = int(n_iters/(len(train_dataset)/batch_size))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
        "validation_data = torch.utils.data.TensorDataset(validation_inputs,validation_labels)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data,batch_size=batch_size)\n",
        "test_data = torch.utils.data.TensorDataset(test_inputs,test_labels)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size)\n",
        "\n",
        "# visualize some images\n",
        "\n",
        "print(\"\\n<\"+\"=\"*25+\"Visualize Images\"+\"=\"*25+\">\\n\")\n",
        "\n",
        "sample_loader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                            batch_size=1, \n",
        "                                            shuffle=True)\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "for i,(j,k) in enumerate(sample_loader):\n",
        "  if(i>5):\n",
        "    break\n",
        "  ax = plt.subplot(3, 3, i+1)\n",
        "  ax.imshow(j.squeeze())\n",
        "  plt.tight_layout()\n",
        "  title = 'Label: {}'.format(k.cpu().numpy())\n",
        "  ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_inputs:  5000\n",
            "validation_inputs:  5000\n",
            "test_labels:  5000\n",
            "validation_labels:  5000\n",
            "train dataset size:  torch.Size([60000, 28, 28])\n",
            "validation dataset size:  torch.Size([5000, 28, 28])\n",
            "test dataset size:  torch.Size([5000, 28, 28])\n",
            "\n",
            "<=========================Visualize Images=========================>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAEnCAYAAAAw+5DXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuwhewvmqs0f",
        "colab_type": "text"
      },
      "source": [
        "## Creating Convolutional Neural Network using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXhnbnKVqrvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    # 1 input channel, 6 output channel, 3X3 square convolution\n",
        "    #Convolution 1\n",
        "    self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2)\n",
        "    self.relu1= nn.ReLU()\n",
        "\n",
        "    #max pool\n",
        "    self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    #Convolution 1\n",
        "    self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
        "    self.relu2= nn.ReLU()\n",
        "\n",
        "    #max pool\n",
        "    self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    # Fully connected 1 (readout)\n",
        "    self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #conv1\n",
        "    out = self.conv1(x)\n",
        "    out = self.relu1(out)\n",
        "\n",
        "    #maxpool1\n",
        "    out = self.maxpool1(out)\n",
        "    \n",
        "    #conv2\n",
        "    out = self.conv2(out)\n",
        "    out = self.relu2(out)\n",
        "\n",
        "    #maxpool2\n",
        "    out = self.maxpool2(out)\n",
        "\n",
        "    # Resize\n",
        "    # Original size: (100, 32, 7, 7)\n",
        "    # out.size(0): 100\n",
        "    # New out size: (100, 32*7*7)\n",
        "    # print(\"out size: \",out.size())\n",
        "    out = out.view(out.size(0), -1)\n",
        "\n",
        "    # Linear function (readout)\n",
        "    out = self.fc1(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1ivSVTNraUX",
        "colab_type": "text"
      },
      "source": [
        "## Train Model Funciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpQ5MNZlobC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model,train_loader,validation_loader,num_epochs,optimizer,criterion,lr=1e-3):\n",
        "  model = model.cuda() if torch.cuda.is_available() else model\n",
        "  model.train()\n",
        "  optimizer = optimizer  \n",
        "  iter = 0\n",
        "  for epoch in range(num_epochs):\n",
        "      for i,(images, labels) in enumerate(train_loader): #(images, labels)\n",
        "\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Load images\n",
        "          images = images.requires_grad_()\n",
        "          #print(images.shape)\n",
        "          # Clear gradients w.r.t. parameters\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward pass to get output/logits\n",
        "          outputs = model(images)\n",
        "\n",
        "          # Calculate Loss: softmax --> cross entropy loss\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Getting gradients w.r.t. parameters\n",
        "          loss.backward()\n",
        "\n",
        "          # Updating parameters\n",
        "          optimizer.step()\n",
        "\n",
        "          iter += 1\n",
        "\n",
        "          if iter % 500 == 0:              \n",
        "              print(\" Training Loss: {}\".format(loss))\n",
        "              test_model(model=model,test_loader=validation_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DESaKaPreoG",
        "colab_type": "text"
      },
      "source": [
        "## Test Model Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51xeEPoxKPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model,test_loader):\n",
        "  # Calculate Accuracy         \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  # Iterate through test dataset\n",
        "  for batch in test_loader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      images, labels = batch\n",
        "\n",
        "      # Load images\n",
        "      images = images.requires_grad_().unsqueeze(1)\n",
        "\n",
        "      # Forward pass only to get logits/output\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Get predictions from the maximum value\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      \n",
        "      # Total number of labels\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # Total correct predictions\n",
        "      correct += (predicted == labels).sum()\n",
        "      \n",
        "  accuracy = 100 * correct / total\n",
        "\n",
        "  # Print Loss\n",
        "  print('Total count: ',total)\n",
        "  print('Total correct: ',correct.cpu().numpy())\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(\"Learning Rate: \",param_group['lr'])\n",
        "  print('Accuracy: {}'.format(accuracy))          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO0tGyEPriEB",
        "colab_type": "text"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "00f24713-f974-43ce-8c73-36bfdc186453",
        "id": "Kn05UYIhmvXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "learning_rate=1e-3\n",
        "model = NeuralNetwork()\n",
        "optimizer=torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"\\n<\"+\"=\"*25+\"Training Model\"+\"=\"*25+\">\\n\")\n",
        "train_model(model=model,train_loader=train_loader,validation_loader=validation_loader,num_epochs=num_epochs,optimizer=optimizer,criterion=criterion,lr=learning_rate)\n",
        "print(\"\\n<\"+\"=\"*25+\"Testing Model\"+\"=\"*25+\">\\n\")\n",
        "test_model(model=model,test_loader=test_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<=========================Training Model=========================>\n",
            "\n",
            " Training Loss: 0.1313277631998062\n",
            "Total count:  5000\n",
            "Total correct:  4860\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 97\n",
            " Training Loss: 0.0429699532687664\n",
            "Total count:  5000\n",
            "Total correct:  4905\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 98\n",
            " Training Loss: 0.04887785017490387\n",
            "Total count:  5000\n",
            "Total correct:  4913\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 98\n",
            " Training Loss: 0.014993314631283283\n",
            "Total count:  5000\n",
            "Total correct:  4914\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 98\n",
            " Training Loss: 0.006276171188801527\n",
            "Total count:  5000\n",
            "Total correct:  4946\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 98\n",
            " Training Loss: 0.24145302176475525\n",
            "Total count:  5000\n",
            "Total correct:  4951\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 99\n",
            "\n",
            "<=========================Testing Model=========================>\n",
            "\n",
            "Total count:  5000\n",
            "Total correct:  4940\n",
            "Learning Rate:  0.001\n",
            "Accuracy: 98\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}